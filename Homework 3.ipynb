{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a43e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psat_w =  tensor(17.4732)\n",
      "psat_d =  tensor(28.8241)\n",
      "Loss for current set is =  tensor(390.4384, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.0427, 1.0356], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(359.9336, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.0841, 1.0706], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(330.9108, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.1242, 1.1049], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(303.3848, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.1631, 1.1385], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(277.3649, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.2007, 1.1713], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(252.8539, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.2370, 1.2032], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(229.8467, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.2721, 1.2342], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(208.3304, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.3058, 1.2642], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(188.2836, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.3383, 1.2932], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(169.6771, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.3695, 1.3212], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(152.4738, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.3995, 1.3481], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(136.6295, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.4281, 1.3739], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(122.0935, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.4555, 1.3985], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(108.8094, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.4816, 1.4221], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(96.7163, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.5065, 1.4446], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(85.7492, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.5301, 1.4660], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(75.8410, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.5526, 1.4862], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(66.9224, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.5739, 1.5054], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(58.9238, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.5941, 1.5235], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(51.7756, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.6132, 1.5406], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(45.4095, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.6311, 1.5567], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(39.7587, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.6481, 1.5718], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(34.7589, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.6641, 1.5860], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(30.3490, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.6791, 1.5992], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(26.4708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.6932, 1.6115], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(23.0697, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7064, 1.6230], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(20.0952, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7188, 1.6337], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(17.5003, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7305, 1.6437], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(15.2420, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7413, 1.6529], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(13.2811, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7515, 1.6614], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(11.5819, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7610, 1.6693], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(10.1124, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7699, 1.6765], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(8.8438, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7782, 1.6832], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(7.7504, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7859, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(6.8093, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7932, 1.6950], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(6.0006, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.7999, 1.7001], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(5.3062, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8062, 1.7048], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(4.7107, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8121, 1.7091], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(4.2004, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8176, 1.7130], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(3.7633, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8227, 1.7166], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(3.3892, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8275, 1.7198], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(3.0690, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8319, 1.7228], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(2.7950, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8361, 1.7254], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(2.5604, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8400, 1.7278], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(2.3596, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8437, 1.7299], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(2.1876, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8471, 1.7318], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(2.0400, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8503, 1.7335], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.9133, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8533, 1.7350], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.8044, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8561, 1.7363], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.7105, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8588, 1.7375], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.6295, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8613, 1.7385], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.5594, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8636, 1.7394], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.4985, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8658, 1.7401], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.4455, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8679, 1.7408], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.3992, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8699, 1.7413], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.3586, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8718, 1.7418], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.3227, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8735, 1.7421], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.2910, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8752, 1.7424], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.2628, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8768, 1.7426], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.2376, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8783, 1.7427], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.2149, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8798, 1.7428], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1944, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8812, 1.7428], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1758, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8825, 1.7428], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1587, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8838, 1.7427], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1430, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8850, 1.7426], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1285, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8861, 1.7424], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1150, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8872, 1.7422], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.1024, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8883, 1.7420], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0906, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8893, 1.7418], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0794, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8903, 1.7415], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0689, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8913, 1.7412], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0588, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8922, 1.7409], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0493, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8931, 1.7406], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0401, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8940, 1.7402], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0313, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8949, 1.7399], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0229, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8957, 1.7395], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0148, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8965, 1.7391], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(1.0069, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8973, 1.7387], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9993, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8980, 1.7383], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9919, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8988, 1.7379], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9848, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.8995, 1.7375], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9778, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9002, 1.7371], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9711, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9009, 1.7366], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9645, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9016, 1.7362], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9581, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9023, 1.7358], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9519, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9029, 1.7354], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9458, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9036, 1.7349], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9398, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9042, 1.7345], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9340, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9048, 1.7341], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9284, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9054, 1.7336], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9229, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9060, 1.7332], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9175, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9066, 1.7327], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9122, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9072, 1.7323], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9070, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9077, 1.7319], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.9020, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9083, 1.7315], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8970, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9088, 1.7310], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8922, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9094, 1.7306], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8875, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9099, 1.7302], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8829, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9104, 1.7298], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8784, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9110, 1.7293], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8740, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9115, 1.7289], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8696, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9120, 1.7285], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8654, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9125, 1.7281], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8613, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9130, 1.7277], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8572, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9134, 1.7273], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8533, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of A values =  tensor([1.9139, 1.7269], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8494, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9144, 1.7265], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8456, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9149, 1.7261], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8419, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9153, 1.7257], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8383, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9158, 1.7253], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8347, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9162, 1.7249], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8312, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9167, 1.7246], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8278, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9171, 1.7242], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8245, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9176, 1.7238], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8212, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9180, 1.7235], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8181, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9184, 1.7231], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8149, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9188, 1.7227], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8119, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9193, 1.7224], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8089, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9197, 1.7220], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8060, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9201, 1.7217], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8031, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9205, 1.7213], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.8003, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9209, 1.7210], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7976, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9213, 1.7206], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7949, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9217, 1.7203], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7922, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9220, 1.7200], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7897, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9224, 1.7196], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7871, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9228, 1.7193], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7847, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9232, 1.7190], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7823, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9235, 1.7187], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7799, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9239, 1.7184], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7776, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9243, 1.7180], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7753, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9246, 1.7177], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7731, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9250, 1.7174], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9253, 1.7171], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7688, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9257, 1.7168], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7668, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9260, 1.7165], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7647, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9263, 1.7162], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7627, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9267, 1.7160], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7608, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9270, 1.7157], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7589, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9273, 1.7154], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7570, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9277, 1.7151], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7552, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9280, 1.7148], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7534, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9283, 1.7146], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7517, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9286, 1.7143], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7499, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9289, 1.7140], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7483, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9292, 1.7138], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7466, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9295, 1.7135], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7450, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9298, 1.7132], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7434, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9301, 1.7130], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7419, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9304, 1.7127], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7404, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9307, 1.7125], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7389, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9310, 1.7122], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7375, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9313, 1.7120], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7361, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9316, 1.7117], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7347, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9319, 1.7115], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7333, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9321, 1.7113], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7320, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9324, 1.7110], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7307, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9327, 1.7108], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7294, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9330, 1.7106], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7282, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9332, 1.7103], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7270, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9335, 1.7101], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7258, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9337, 1.7099], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7246, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9340, 1.7097], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7235, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9343, 1.7094], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7224, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9345, 1.7092], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7213, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9348, 1.7090], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7202, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9350, 1.7088], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7191, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9352, 1.7086], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7181, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9355, 1.7084], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7171, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9357, 1.7082], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7161, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9360, 1.7080], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7152, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9362, 1.7078], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7142, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9364, 1.7076], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7133, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9367, 1.7074], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7124, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9369, 1.7072], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7115, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9371, 1.7070], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7106, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9373, 1.7068], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7098, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9376, 1.7066], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7090, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9378, 1.7064], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7082, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9380, 1.7063], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7074, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9382, 1.7061], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7066, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9384, 1.7059], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7058, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9386, 1.7057], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7051, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9388, 1.7055], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7043, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9390, 1.7054], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7036, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9392, 1.7052], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7029, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9394, 1.7050], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7022, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9396, 1.7049], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7016, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9398, 1.7047], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7009, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9400, 1.7045], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.7003, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9402, 1.7044], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6996, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9404, 1.7042], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6990, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9406, 1.7040], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6984, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9408, 1.7039], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6978, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9410, 1.7037], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6973, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9411, 1.7036], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6967, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9413, 1.7034], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6961, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9415, 1.7033], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6956, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9417, 1.7031], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6951, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9418, 1.7030], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6945, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9420, 1.7028], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6940, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9422, 1.7027], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6935, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9424, 1.7025], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6931, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9425, 1.7024], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6926, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9427, 1.7023], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6921, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9429, 1.7021], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6916, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9430, 1.7020], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6912, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9432, 1.7019], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6908, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9433, 1.7017], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6903, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9435, 1.7016], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6899, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9437, 1.7015], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6895, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9438, 1.7013], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6891, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9440, 1.7012], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6887, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9441, 1.7011], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6883, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9443, 1.7009], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6879, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9444, 1.7008], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6876, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9446, 1.7007], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6872, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9447, 1.7006], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6869, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9448, 1.7005], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6865, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of A values =  tensor([1.9450, 1.7003], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6862, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9451, 1.7002], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6858, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9453, 1.7001], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6855, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9454, 1.7000], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6852, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9455, 1.6999], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6849, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9457, 1.6998], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6846, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9458, 1.6996], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6843, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9459, 1.6995], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6840, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9461, 1.6994], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6837, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9462, 1.6993], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6834, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9463, 1.6992], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6831, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9464, 1.6991], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6829, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9466, 1.6990], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6826, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9467, 1.6989], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6823, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9468, 1.6988], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6821, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9469, 1.6987], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6818, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9471, 1.6986], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6816, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9472, 1.6985], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6814, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9473, 1.6984], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6811, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9474, 1.6983], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6809, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9475, 1.6982], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6807, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9476, 1.6981], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6805, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9478, 1.6980], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6802, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9479, 1.6979], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6800, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9480, 1.6978], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6798, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9481, 1.6977], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6796, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9482, 1.6977], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6794, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9483, 1.6976], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6792, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9484, 1.6975], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6790, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9485, 1.6974], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6789, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9486, 1.6973], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6787, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9487, 1.6972], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6785, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9488, 1.6971], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6783, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9489, 1.6970], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6782, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9490, 1.6970], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6780, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9491, 1.6969], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6778, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9492, 1.6968], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6777, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9493, 1.6967], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6775, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9494, 1.6966], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6774, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9495, 1.6966], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6772, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9496, 1.6965], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6771, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9497, 1.6964], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6769, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9498, 1.6963], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6768, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9499, 1.6963], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6767, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9499, 1.6962], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6765, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9500, 1.6961], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6764, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9501, 1.6960], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6763, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9502, 1.6960], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6761, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9503, 1.6959], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6760, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9504, 1.6958], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6759, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9505, 1.6958], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6758, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9505, 1.6957], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6757, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9506, 1.6956], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6755, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9507, 1.6955], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6754, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9508, 1.6955], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6753, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9509, 1.6954], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6752, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9510, 1.6953], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6751, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9510, 1.6953], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6750, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9511, 1.6952], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6749, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9512, 1.6952], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6748, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9513, 1.6951], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6747, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9513, 1.6950], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6746, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9514, 1.6950], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6745, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9515, 1.6949], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6744, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9516, 1.6949], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6743, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9516, 1.6948], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6743, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9517, 1.6947], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6742, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9518, 1.6947], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6741, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9518, 1.6946], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6740, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9519, 1.6946], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6739, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9520, 1.6945], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6739, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9520, 1.6944], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6738, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9521, 1.6944], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6737, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9522, 1.6943], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6736, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9522, 1.6943], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6736, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9523, 1.6942], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6735, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9524, 1.6942], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6734, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9524, 1.6941], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6734, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9525, 1.6941], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6733, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9526, 1.6940], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6732, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9526, 1.6940], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6732, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9527, 1.6939], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6731, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9527, 1.6939], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6730, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9528, 1.6938], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6730, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9529, 1.6938], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6729, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9529, 1.6937], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6729, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9530, 1.6937], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6728, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9530, 1.6936], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6728, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9531, 1.6936], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6727, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9531, 1.6935], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6727, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9532, 1.6935], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6726, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9532, 1.6934], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6726, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9533, 1.6934], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6725, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9534, 1.6934], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6725, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9534, 1.6933], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6724, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9535, 1.6933], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6724, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9535, 1.6932], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6723, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9536, 1.6932], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6723, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9536, 1.6931], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6722, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9537, 1.6931], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6722, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9537, 1.6931], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6722, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9538, 1.6930], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6721, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9538, 1.6930], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6721, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9539, 1.6929], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6720, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9539, 1.6929], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6720, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9540, 1.6929], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6720, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9540, 1.6928], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6719, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9540, 1.6928], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6719, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9541, 1.6927], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6719, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9541, 1.6927], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6718, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9542, 1.6927], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6718, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9542, 1.6926], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6717, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9543, 1.6926], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6717, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9543, 1.6926], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6717, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9544, 1.6925], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6717, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9544, 1.6925], requires_grad=True)\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for current set is =  tensor(0.6716, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9544, 1.6925], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6716, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9545, 1.6924], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6716, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9545, 1.6924], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6715, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9546, 1.6924], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6715, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9546, 1.6923], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6715, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9546, 1.6923], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6715, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9547, 1.6923], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6714, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9547, 1.6922], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6714, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9548, 1.6922], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6714, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9548, 1.6922], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6714, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9548, 1.6921], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6713, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9549, 1.6921], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6713, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9549, 1.6921], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6713, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9549, 1.6920], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6713, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9550, 1.6920], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6712, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9550, 1.6920], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6712, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9551, 1.6920], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6712, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9551, 1.6919], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6712, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9551, 1.6919], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6712, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9552, 1.6919], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6711, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9552, 1.6918], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6711, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9552, 1.6918], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6711, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9553, 1.6918], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6711, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9553, 1.6918], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6711, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9553, 1.6917], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9554, 1.6917], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9554, 1.6917], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9554, 1.6917], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9555, 1.6916], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9555, 1.6916], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6710, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9555, 1.6916], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9555, 1.6915], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9556, 1.6915], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9556, 1.6915], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9556, 1.6915], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9557, 1.6915], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9557, 1.6914], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6709, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9557, 1.6914], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9557, 1.6914], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9558, 1.6914], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9558, 1.6913], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9558, 1.6913], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9559, 1.6913], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9559, 1.6913], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9559, 1.6912], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6708, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9559, 1.6912], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9560, 1.6912], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9560, 1.6912], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9560, 1.6912], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9560, 1.6911], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9561, 1.6911], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9561, 1.6911], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9561, 1.6911], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9561, 1.6911], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9562, 1.6910], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6707, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9562, 1.6910], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9562, 1.6910], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9562, 1.6910], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9563, 1.6910], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9563, 1.6909], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9563, 1.6909], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9563, 1.6909], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9563, 1.6909], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9564, 1.6909], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9564, 1.6909], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9564, 1.6908], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9564, 1.6908], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6706, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9564, 1.6908], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9565, 1.6908], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9565, 1.6908], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9565, 1.6908], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9565, 1.6907], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9565, 1.6907], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9566, 1.6907], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9566, 1.6907], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9566, 1.6907], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9566, 1.6907], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9566, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9567, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9567, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9567, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9567, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9567, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9568, 1.6906], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6705, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9568, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9568, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9568, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9568, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9568, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6905], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9569, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9570, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9570, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9570, 1.6904], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9570, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9570, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9570, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6903], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of A values =  tensor([1.9571, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6704, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9571, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9572, 1.6902], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9573, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6901], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9574, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6900], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9575, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6899], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9576, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6898], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6703, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9577, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9578, 1.6897], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9579, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6896], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9580, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6895], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9581, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6894], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9582, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6893], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9583, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "Loss for current set is =  tensor(0.6702, grad_fn=<SumBackward0>)\n",
      "New set of A values =  tensor([1.9584, 1.6892], requires_grad=True)\n",
      " \n",
      "The final data set for A =  [1.958413  1.6891907]\n",
      "The loss at this location =  0.6702072\n",
      "The gradiant at this location =  tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-a55ab0743407>:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return x*np.exp(A12*(A21*y/(A12*x+A21*y))**2)*psat_w + y*np.exp(A21*(A12*x/(A12*x+A21*y))**2)*psat_d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x1bcc19ee2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Problem 1\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Constants\n",
    "T = 20 #C\n",
    "a_water = t.tensor([8.07131, 1730.63, 233.426])\n",
    "a_dioxane = t.tensor([7.43155, 1554.679, 240.337])\n",
    "\n",
    "psat_w = 10**(a_water[0]-(a_water[1])/(T+a_water[2]))\n",
    "psat_d = 10**(a_dioxane[0]-(a_dioxane[1])/(T+a_dioxane[2]))\n",
    "print(\"psat_w = \", psat_w)\n",
    "print(\"psat_d = \", psat_d)\n",
    "\n",
    "# Measured Data Table\n",
    "x1 = t.tensor([0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1])\n",
    "x2 = t.tensor([1, .9, .8, .7, .6, .5, .4, .3, .2, .1, 0])\n",
    "p = t.tensor([28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5])\n",
    "\n",
    "A_opt = Variable(t.tensor([1.0, 1.0]), requires_grad=True)\n",
    "\n",
    "a = .0001\n",
    "\n",
    "# Functions\n",
    "def getPoint(A12, A21):\n",
    "    return x1*t.exp(A12*(A21*x2/(A12*x1+A21*x2))**2)*psat_w + x2*t.exp(A21*(A12*x1/(A12*x1+A21*x2))**2)*psat_d\n",
    "\n",
    "def loss_(p1):\n",
    "    return (p1 - p)**2\n",
    "\n",
    "# Since not linear, there is no analytical solution. Solve using gradient descent or Newton's method\n",
    "for i in range(1000):\n",
    "    pred = t.zeros(1,11)\n",
    "    loss_pred = t.zeros(1,11)\n",
    "\n",
    "    pred = getPoint(A_opt[0], A_opt[1])\n",
    "\n",
    "    loss_pred = loss_(pred)\n",
    "\n",
    "    loss = t.sum(loss_pred)\n",
    "    print(\"Loss for current set is = \", loss)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with t.no_grad():\n",
    "        A_opt -= a * A_opt.grad\n",
    "        A_opt.grad.zero_()\n",
    "\n",
    "    print(\"New set of A values = \", A_opt)\n",
    "    print(\" \")\n",
    "\n",
    "print(\"The final data set for A = \", A_opt.data.numpy())\n",
    "print(\"The loss at this location = \", loss.data.numpy())\n",
    "print(\"The gradiant at this location = \", A_opt.grad)\n",
    "\n",
    "\n",
    "# Compare your optimized model with the data. Does your model fit well with the data\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A12 = 1.958413\n",
    "A21 = 1.6891907\n",
    "psat_w = 17.47325\n",
    "psat_d = 28.8241\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "\n",
    "def f(x,y):\n",
    "    return x*np.exp(A12*(A21*y/(A12*x+A21*y))**2)*psat_w + y*np.exp(A21*(A12*x/(A12*x+A21*y))**2)*psat_d\n",
    "\n",
    "x = np.linspace(0,2,100)\n",
    "y = np.linspace(0,2,100)\n",
    "\n",
    "X, Y = np.meshgrid(x,y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "ax.contour3D(X,Y,Z,75)\n",
    "\n",
    "xdata = t.tensor([0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1])\n",
    "ydata = t.tensor([1, .9, .8, .7, .6, .5, .4, .3, .2, .1, 0])\n",
    "zdata = t.tensor([28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5])\n",
    "\n",
    "ax.scatter3D(xdata, ydata, zdata, color='black')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e505b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    x1     |    x2     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m-0.4979  \u001b[0m | \u001b[0m 0.8813  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-110.1   \u001b[0m | \u001b[0m-2.999   \u001b[0m | \u001b[0m-0.7907  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-26.91   \u001b[0m | \u001b[0m-2.119   \u001b[0m | \u001b[0m-1.631   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.856   \u001b[0m | \u001b[0m-1.882   \u001b[0m | \u001b[0m-0.6178  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.054   \u001b[0m | \u001b[0m-0.6194  \u001b[0m | \u001b[0m 0.1553  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.5211  \u001b[0m | \u001b[95m-0.4848  \u001b[0m | \u001b[95m 0.7409  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-11.28   \u001b[0m | \u001b[0m-1.773   \u001b[0m | \u001b[0m 1.512   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-66.76   \u001b[0m | \u001b[0m-2.836   \u001b[0m | \u001b[0m 0.6819  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.5377  \u001b[0m | \u001b[0m-0.4962  \u001b[0m | \u001b[0m 0.2348  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-12.02   \u001b[0m | \u001b[0m-2.158   \u001b[0m | \u001b[0m-1.208   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-6.707   \u001b[0m | \u001b[0m-0.6913  \u001b[0m | \u001b[0m-1.287   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-4.507   \u001b[0m | \u001b[0m 1.223   \u001b[0m | \u001b[0m 1.081   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.5198  \u001b[0m | \u001b[0m 1.354   \u001b[0m | \u001b[0m-0.6292  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-65.32   \u001b[0m | \u001b[0m 2.812   \u001b[0m | \u001b[0m 0.1161  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-48.23   \u001b[0m | \u001b[0m 1.016   \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-49.11   \u001b[0m | \u001b[0m 0.3388  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-1.532   \u001b[0m | \u001b[0m 0.7023  \u001b[0m | \u001b[0m 0.103   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-68.92   \u001b[0m | \u001b[0m 2.385   \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-150.9   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-150.9   \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.626   \u001b[0m | \u001b[95m 0.3658  \u001b[0m | \u001b[95m-0.8456  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.0896  \u001b[0m | \u001b[0m-1.509   \u001b[0m | \u001b[0m 0.7057  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-48.22   \u001b[0m | \u001b[0m-1.022   \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.243   \u001b[0m | \u001b[0m 1.573   \u001b[0m | \u001b[0m 0.2764  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-4.215   \u001b[0m | \u001b[0m-1.416   \u001b[0m | \u001b[0m-1.051   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-48.84   \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.1817  \u001b[0m | \u001b[0m-0.3741  \u001b[0m | \u001b[0m-0.6042  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.276   \u001b[0m | \u001b[0m 0.3921  \u001b[0m | \u001b[0m 0.8941  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-2.63    \u001b[0m | \u001b[0m-1.208   \u001b[0m | \u001b[0m 1.144   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.447   \u001b[0m | \u001b[0m-1.332   \u001b[0m | \u001b[0m-0.2503  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.774   \u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m-0.508   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-1.988   \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 0.5836  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.1814  \u001b[0m | \u001b[0m 0.1361  \u001b[0m | \u001b[0m-0.2427  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-1.987   \u001b[0m | \u001b[0m 1.345   \u001b[0m | \u001b[0m-0.1736  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-2.024   \u001b[0m | \u001b[0m 0.9383  \u001b[0m | \u001b[0m-1.093   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5136  \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 0.4528  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.4781  \u001b[0m | \u001b[0m-1.839   \u001b[0m | \u001b[0m 0.9853  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-1.97    \u001b[0m | \u001b[0m-1.837   \u001b[0m | \u001b[0m 0.1696  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.7325  \u001b[0m | \u001b[0m-0.1254  \u001b[0m | \u001b[0m-1.058   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-2.699   \u001b[0m | \u001b[0m 1.764   \u001b[0m | \u001b[0m 0.8146  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.4919  \u001b[0m | \u001b[0m-0.06087 \u001b[0m | \u001b[0m 0.9332  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-1.628   \u001b[0m | \u001b[0m-0.869   \u001b[0m | \u001b[0m-0.7465  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.7302  \u001b[0m | \u001b[0m-0.9863  \u001b[0m | \u001b[0m 0.5863  \u001b[0m |\n",
      "| \u001b[95m 44      \u001b[0m | \u001b[95m 1.011   \u001b[0m | \u001b[95m 0.02789 \u001b[0m | \u001b[95m-0.6823  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-2.237   \u001b[0m | \u001b[0m 1.43    \u001b[0m | \u001b[0m 0.6894  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-1.75    \u001b[0m | \u001b[0m-1.419   \u001b[0m | \u001b[0m 0.2248  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-1.557   \u001b[0m | \u001b[0m-1.56    \u001b[0m | \u001b[0m 1.114   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.5286  \u001b[0m | \u001b[0m-1.868   \u001b[0m | \u001b[0m 0.5935  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.2196  \u001b[0m | \u001b[0m-0.2621  \u001b[0m | \u001b[0m-0.1463  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-4.008   \u001b[0m | \u001b[0m-1.796   \u001b[0m | \u001b[0m-0.997   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.4914  \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 0.5372  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.526   \u001b[0m | \u001b[0m 1.042   \u001b[0m | \u001b[0m-0.763   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-1.25    \u001b[0m | \u001b[0m 1.731   \u001b[0m | \u001b[0m-0.3005  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.2052  \u001b[0m | \u001b[0m 0.4553  \u001b[0m | \u001b[0m-0.4877  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.6786  \u001b[0m | \u001b[0m-0.4609  \u001b[0m | \u001b[0m-0.9229  \u001b[0m |\n",
      "| \u001b[95m 56      \u001b[0m | \u001b[95m 1.012   \u001b[0m | \u001b[95m-0.1067  \u001b[0m | \u001b[95m 0.6646  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-2.143   \u001b[0m | \u001b[0m-1.514   \u001b[0m | \u001b[0m-0.6249  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-2.442   \u001b[0m | \u001b[0m 0.4995  \u001b[0m | \u001b[0m-1.178   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.1472  \u001b[0m | \u001b[0m 0.6909  \u001b[0m | \u001b[0m-0.8758  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.3415  \u001b[0m | \u001b[0m 0.2988  \u001b[0m | \u001b[0m 0.07199 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.4237  \u001b[0m | \u001b[0m-0.8351  \u001b[0m | \u001b[0m 0.8718  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7513  \u001b[0m | \u001b[0m 0.1704  \u001b[0m | \u001b[0m 0.7389  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-2.264   \u001b[0m | \u001b[0m-1.707   \u001b[0m | \u001b[0m-0.2564  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-1.853   \u001b[0m | \u001b[0m 0.8003  \u001b[0m | \u001b[0m 0.8924  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-1.402   \u001b[0m | \u001b[0m-0.7172  \u001b[0m | \u001b[0m-0.3253  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.1302  \u001b[0m | \u001b[0m-0.0821  \u001b[0m | \u001b[0m 0.1915  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.6709  \u001b[0m | \u001b[0m-0.1571  \u001b[0m | \u001b[0m-0.8132  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.5921  \u001b[0m | \u001b[0m 0.1168  \u001b[0m | \u001b[0m-0.9162  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m-0.1106  \u001b[0m | \u001b[0m-0.4563  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.878   \u001b[0m | \u001b[0m-0.242   \u001b[0m | \u001b[0m 0.8062  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-2.78    \u001b[0m | \u001b[0m 1.871   \u001b[0m | \u001b[0m 0.3933  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.2056  \u001b[0m | \u001b[0m-1.73    \u001b[0m | \u001b[0m 0.8138  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.5975  \u001b[0m | \u001b[0m-1.665   \u001b[0m | \u001b[0m 0.4656  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.822   \u001b[0m | \u001b[0m 0.217   \u001b[0m | \u001b[0m-0.5726  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.5523  \u001b[0m | \u001b[0m-1.199   \u001b[0m | \u001b[0m 0.8327  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m-0.2661  \u001b[0m | \u001b[0m 0.4905  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.9963  \u001b[0m | \u001b[0m 1.542   \u001b[0m | \u001b[0m-0.3916  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.2843  \u001b[0m | \u001b[0m 1.476   \u001b[0m | \u001b[0m-0.9111  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.1049  \u001b[0m | \u001b[0m 1.705   \u001b[0m | \u001b[0m-0.6905  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.01691 \u001b[0m | \u001b[0m 1.542   \u001b[0m | \u001b[0m-0.7155  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-0.6278  \u001b[0m | \u001b[0m 0.5094  \u001b[0m | \u001b[0m-0.2095  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.9201  \u001b[0m | \u001b[0m 0.01106 \u001b[0m | \u001b[0m 0.7956  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9706  \u001b[0m | \u001b[0m 0.2166  \u001b[0m | \u001b[0m-0.7102  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.6857  \u001b[0m | \u001b[0m-0.07245 \u001b[0m | \u001b[0m 0.4627  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m-0.2857  \u001b[0m | \u001b[0m-0.6553  \u001b[0m | \u001b[0m 0.4975  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m-0.1336  \u001b[0m | \u001b[0m-0.6205  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.9502  \u001b[0m | \u001b[0m 0.04467 \u001b[0m | \u001b[0m 0.6672  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.6023  \u001b[0m | \u001b[0m 0.4463  \u001b[0m | \u001b[0m-0.714   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.922   \u001b[0m | \u001b[0m 0.008069\u001b[0m | \u001b[0m-0.8032  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.9826  \u001b[0m | \u001b[0m-0.09726 \u001b[0m | \u001b[0m 0.7865  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.8163  \u001b[0m | \u001b[0m 0.03224 \u001b[0m | \u001b[0m-0.5276  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.8269  \u001b[0m | \u001b[0m-0.3106  \u001b[0m | \u001b[0m 0.6654  \u001b[0m |\n",
      "| \u001b[95m 93      \u001b[0m | \u001b[95m 1.021   \u001b[0m | \u001b[95m 0.1089  \u001b[0m | \u001b[95m-0.7473  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.4924  \u001b[0m | \u001b[0m 0.2708  \u001b[0m | \u001b[0m 0.6156  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9947  \u001b[0m | \u001b[0m 0.0946  \u001b[0m | \u001b[0m-0.6425  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9785  \u001b[0m | \u001b[0m-0.2039  \u001b[0m | \u001b[0m 0.6967  \u001b[0m |\n",
      "| \u001b[95m 97      \u001b[0m | \u001b[95m 1.021   \u001b[0m | \u001b[95m-0.04092 \u001b[0m | \u001b[95m 0.7225  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.967   \u001b[0m | \u001b[0m-0.0521  \u001b[0m | \u001b[0m 0.6191  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.9612  \u001b[0m | \u001b[0m-0.04359 \u001b[0m | \u001b[0m-0.7119  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.9454  \u001b[0m | \u001b[0m 0.2186  \u001b[0m | \u001b[0m-0.7722  \u001b[0m |\n",
      "| \u001b[95m 101     \u001b[0m | \u001b[95m 1.028   \u001b[0m | \u001b[95m-0.1186  \u001b[0m | \u001b[95m 0.7101  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-0.6523  \u001b[0m | \u001b[0m 1.26    \u001b[0m | \u001b[0m-0.9034  \u001b[0m |\n",
      "| \u001b[95m 103     \u001b[0m | \u001b[95m 1.031   \u001b[0m | \u001b[95m 0.08752 \u001b[0m | \u001b[95m-0.7236  \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.9426  \u001b[0m | \u001b[0m-0.1785  \u001b[0m | \u001b[0m 0.6284  \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 1.014   \u001b[0m | \u001b[0m 0.1305  \u001b[0m | \u001b[0m-0.6774  \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 1.023   \u001b[0m | \u001b[0m 0.04556 \u001b[0m | \u001b[0m-0.7187  \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m-0.07226 \u001b[0m | \u001b[0m 0.7213  \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.007754\u001b[0m | \u001b[0m 0.002889\u001b[0m | \u001b[0m-0.0438  \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 1.015   \u001b[0m | \u001b[0m-0.1566  \u001b[0m | \u001b[0m 0.7187  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.8463  \u001b[0m | \u001b[0m 0.3056  \u001b[0m | \u001b[0m-0.6796  \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 1.024   \u001b[0m | \u001b[0m 0.1335  \u001b[0m | \u001b[0m-0.7136  \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m-0.04071 \u001b[0m | \u001b[0m 0.6962  \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.9862  \u001b[0m | \u001b[0m 0.1256  \u001b[0m | \u001b[0m-0.7817  \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.9595  \u001b[0m | \u001b[0m-0.01864 \u001b[0m | \u001b[0m-0.6463  \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m-0.1075  \u001b[0m | \u001b[0m 0.7149  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 1.027   \u001b[0m | \u001b[0m 0.08628 \u001b[0m | \u001b[0m-0.6879  \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m 0.04827 \u001b[0m | \u001b[0m-0.7081  \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m-0.09643 \u001b[0m | \u001b[0m 0.6964  \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 1.027   \u001b[0m | \u001b[0m-0.1071  \u001b[0m | \u001b[0m 0.7332  \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m-0.06723 \u001b[0m | \u001b[0m 0.7108  \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m-0.1632  \u001b[0m | \u001b[0m 0.7521  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m 0.132   \u001b[0m | \u001b[0m-0.7113  \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 1.023   \u001b[0m | \u001b[0m 0.07093 \u001b[0m | \u001b[0m-0.7408  \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m-0.717   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m-0.04712 \u001b[0m | \u001b[0m 0.6784  \u001b[0m |\n",
      "| \u001b[95m 126     \u001b[0m | \u001b[95m 1.031   \u001b[0m | \u001b[95m-0.09395 \u001b[0m | \u001b[95m 0.7034  \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 1.023   \u001b[0m | \u001b[0m 0.05357 \u001b[0m | \u001b[0m-0.6893  \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m-0.01313 \u001b[0m | \u001b[0m 0.7189  \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m-0.08506 \u001b[0m | \u001b[0m 0.7295  \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 1.031   \u001b[0m | \u001b[0m 0.0738  \u001b[0m | \u001b[0m-0.7144  \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m-0.1179  \u001b[0m | \u001b[0m 0.706   \u001b[0m |\n",
      "| \u001b[95m 132     \u001b[0m | \u001b[95m 1.031   \u001b[0m | \u001b[95m 0.08622 \u001b[0m | \u001b[95m-0.7163  \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m-0.06025 \u001b[0m | \u001b[0m 0.7406  \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.0629  \u001b[0m | \u001b[0m-0.7384  \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 1.026   \u001b[0m | \u001b[0m 0.1266  \u001b[0m | \u001b[0m-0.7231  \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m 0.08478 \u001b[0m | \u001b[0m-0.692   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 0.1622  \u001b[0m | \u001b[0m-0.6827  \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m-0.0984  \u001b[0m | \u001b[0m 0.6857  \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m-0.7354  \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m 0.09254 \u001b[0m | \u001b[0m-0.6936  \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m-0.05583 \u001b[0m | \u001b[0m 0.6802  \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 1.027   \u001b[0m | \u001b[0m-0.06724 \u001b[0m | \u001b[0m 0.7304  \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 1.026   \u001b[0m | \u001b[0m-0.1268  \u001b[0m | \u001b[0m 0.7211  \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 1.013   \u001b[0m | \u001b[0m 0.0322  \u001b[0m | \u001b[0m-0.7352  \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 1.027   \u001b[0m | \u001b[0m-0.1023  \u001b[0m | \u001b[0m 0.7354  \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 1.019   \u001b[0m | \u001b[0m-0.1127  \u001b[0m | \u001b[0m 0.6768  \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m-0.07168 \u001b[0m | \u001b[0m 0.6947  \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 0.4653  \u001b[0m | \u001b[0m 0.1362  \u001b[0m | \u001b[0m 0.8897  \u001b[0m |\n",
      "| \u001b[95m 149     \u001b[0m | \u001b[95m 1.031   \u001b[0m | \u001b[95m 0.09181 \u001b[0m | \u001b[95m-0.7167  \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m-0.09214 \u001b[0m | \u001b[0m 0.7001  \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m 0.1001  \u001b[0m | \u001b[0m-0.6962  \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 0.08855 \u001b[0m | \u001b[0m-0.725   \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m 0.07132 \u001b[0m | \u001b[0m-0.6983  \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 0.04814 \u001b[0m | \u001b[0m 0.5733  \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 1.016   \u001b[0m | \u001b[0m 0.1534  \u001b[0m | \u001b[0m-0.7226  \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 1.031   \u001b[0m | \u001b[0m 0.09342 \u001b[0m | \u001b[0m-0.7179  \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m-0.1061  \u001b[0m | \u001b[0m 0.7177  \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 1.031   \u001b[0m | \u001b[0m-0.08525 \u001b[0m | \u001b[0m 0.7061  \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m-0.09898 \u001b[0m | \u001b[0m 0.7318  \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m-0.06721 \u001b[0m | \u001b[0m 0.7067  \u001b[0m |\n",
      "=================================================\n",
      "Using Bayesian Optimization on the function returns:\n",
      "X1 =  0.0918079780344101\n",
      "X2 =  -0.7167301500347611\n",
      "Y =  -1.0314847263331826\n",
      "With a gradient =  [ 0.01124661 -0.06532344]\n",
      " \n",
      "Using gradient descent to refine values returns:\n",
      "X1 =  0.09077434518912046\n",
      "X2 =  -0.7132673143955719\n",
      "Y =  -1.0316225759431568\n",
      "With a gradient =  [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Set bounds\n",
    "bounds = {'x1': (-3,3), 'x2': (-2,2)}\n",
    "\n",
    "# Set function\n",
    "def min_func(x1, x2):\n",
    "    return -1*((4-2.1*x1**2+(x1**4)/3)*x1**2+x1*x2+(-4+4*x2**2)*x2**2)\n",
    "\n",
    "def func(x1, x2):\n",
    "    return (4-2.1*x1**2+(x1**4)/3)*x1**2+x1*x2+(-4+4*x2**2)*x2**2\n",
    "\n",
    "# Bayesian Optimization\n",
    "optimizer = BayesianOptimization(f = min_func, pbounds = bounds, random_state = 1)\n",
    "optimizer.maximize(init_points = 10, n_iter = 150)\n",
    "\n",
    "# Extract Optimal Values\n",
    "best_values = optimizer.max\n",
    "best_target = best_values['target']\n",
    "best_target = -1*best_target\n",
    "best_inputs = best_values['params']\n",
    "best_x1 = best_inputs['x1']\n",
    "best_x2 = best_inputs['x2']\n",
    "\n",
    "print(\"Using Bayesian Optimization on the function returns:\")\n",
    "print(\"X1 = \", best_x1)\n",
    "print(\"X2 = \", best_x2)\n",
    "print(\"Y = \", best_target)\n",
    "\n",
    "# Test Values Using Gradient\n",
    "x_opt = Variable(t.tensor([best_x1, best_x2]), requires_grad=True)\n",
    "loss = (4-2.1*x_opt[0]**2+(x_opt[0]**4)/3)*x_opt[0]**2+x_opt[0]*x_opt[1]+(-4+4*x_opt[1]**2)*x_opt[1]**2\n",
    "loss.backward()\n",
    "print(\"With a gradient = \", x_opt.grad.numpy())\n",
    "print(\" \")\n",
    "\n",
    "# Refine Using Gradient Descent\n",
    "a = .01\n",
    "for i in range(10):\n",
    "    loss = (4-2.1*x_opt[0]**2+(x_opt[0]**4)/3)*x_opt[0]**2+x_opt[0]*x_opt[1]+(-4+4*x_opt[1]**2)*x_opt[1]**2\n",
    "    loss.backward()\n",
    "    with t.no_grad():\n",
    "        x_opt -= a * x_opt.grad\n",
    "        x_opt.grad.zero_()\n",
    "\n",
    "ref_val = x_opt.data.numpy()\n",
    "ref_x1 = ref_val[0]\n",
    "ref_x2 = ref_val[1]\n",
    "ref_target = (4-2.1*ref_val[0]**2+(ref_val[0]**4)/3)*ref_val[0]**2+ref_val[0]*ref_val[1]+(-4+4*ref_val[1]**2)*ref_val[1]**2\n",
    "\n",
    "print(\"Using gradient descent to refine values returns:\")\n",
    "print(\"X1 = \", ref_x1)\n",
    "print(\"X2 = \", ref_x2)\n",
    "print(\"Y = \", ref_target)\n",
    "print(\"With a gradient = \", x_opt.grad.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95517d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
